{"nbformat": 4, "nbformat_minor": 5, "metadata": {"colab": {"name": "Showdown_EV_Colab.ipynb"}, "kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"name": "python"}}, "cells": [{"id": "22be9b16", "cell_type": "markdown", "source": "# DraftKings Showdown EV \u2014 Colab Notebook\nPaste your RAW GitHub CSV URLs in the next cell and run top-to-bottom.", "metadata": {}}, {"id": "923532a3", "cell_type": "code", "metadata": {}, "execution_count": null, "source": "\n# === 1) Paste your RAW GitHub URLs here ===\nPROJECTIONS_URL = \"https://raw.githubusercontent.com/<user>/<repo>/<branch>/projections.csv\"\nLEVERAGE_URL    = \"https://raw.githubusercontent.com/<user>/<repo>/<branch>/leverage.csv\"\nPERCENTILES_URL = \"https://raw.githubusercontent.com/<user>/<repo>/<branch>/percentiles.csv\"\n\n# SimConfig overrides (optional)\nCFG_KW = dict(\n    n_sims=5000,             # increase for more accuracy if runtime allows\n    candidate_pool_size=4000,\n    max_overlap=3,\n    leave_salary_max=3500,\n    rng_seed=123,\n)\nprint(\"URLs set. If you need to use a blob URL, convert it to RAW (raw.githubusercontent.com).\")\n", "outputs": []}, {"id": "cf96021d", "cell_type": "code", "metadata": {}, "execution_count": null, "source": "import os, textwrap\nbase = '/content/showdown_ev/showdown'\nos.makedirs(base, exist_ok=True)\nopen(os.path.join(base, '__init__.py'), 'w', encoding='utf-8').write(r'''from .config import SimConfig\nfrom .data_io import load_projections, load_leverage, load_percentiles, merge_inputs\nfrom .percentiles import QuantileSampler\nfrom .correlation import build_correlation\nfrom .lineup import Lineup, is_valid_lineup, apply_cpt_salary, validate_player_pool\nfrom .generator import CandidateGenerator\nfrom .opponent import OpponentField\nfrom .ev import EVSimulator\nfrom .portfolio import PortfolioOptimizer\n''')\nopen(os.path.join(base, 'config.py'), 'w', encoding='utf-8').write(r'''from dataclasses import dataclass\n\n@dataclass\nclass SimConfig:\n    # Simulation controls\n    n_sims: int = 5000                 # Monte Carlo slates\n    field_size: int = 475              # total entries in contest\n    our_entries: int = 10              # how many lineups we submit\n    prize_first: float = 100.0         # total prize to split among 1st-place ties\n    mode: str = \"quantile\"             # \"quantile\" or \"stats\" (stats placeholder)\n    dup_penalty: float = 0.15          # penalize dup-prone lineups (0..1)\n    max_salary: int = 50000            # DK cap\n    leave_salary_max: int = 3500       # max salary left on table for our candidates\n    max_overlap: int = 3               # max shared players among our 10 lineups\n    enforce_unique_cpt: bool = False   # can toggle; portfolio optimizer will balance naturally\n    rng_seed: int = 42                 # reproducibility\n\n    # Candidate generation\n    candidate_pool_size: int = 4000    # number of candidate lineups for us\n    cpt_top_k: int = 15                # limit captain choices to top-K by p50 points\n    flex_top_k: int = 35               # limit flex pool by p50 points (per team combined)\n\n    # Correlation knobs for Gaussian copula (used in quantile mode)\n    base_same_team: float = 0.20\n    qb_receiver_boost: float = 0.25\n    dst_vs_opp_offense: float = -0.30\n    dsts_mutual: float = -0.20\n    k_vs_offense: float = 0.05\n    cross_team_baseline: float = 0.05\n\n    # Opponent field modeling\n    field_model: str = \"A\"             # \"A\" sampling by ownership, \"B\" optimizer-like\n    field_portfolio_size: int = 8000   # bank of distinct field lineups to sample from\n    field_noise_sd: float = 2.0        # points of noise in optimizer-like mode\n''')\nopen(os.path.join(base, 'correlation.py'), 'w', encoding='utf-8').write(r'''import numpy as np\nimport pandas as pd\n\ndef _pos_group(pos: str) -> str:\n    pos = pos.upper()\n    if pos in ['QB','RB','WR','TE','K','DST']:\n        return pos\n    return 'OTH'\n\ndef build_correlation(players_df: pd.DataFrame, cfg) -> np.ndarray:\n    n = len(players_df)\n    C = np.eye(n)\n    # Precompute quick lookups\n    team = players_df['Team'].to_numpy()\n    pos  = players_df['Pos'].to_numpy()\n    name = players_df['Player'].to_numpy()\n\n    # Identify QBs by team (for receiver boost)\n    qb_idx_by_team = {}\n    for i,(t,p) in enumerate(zip(team,pos)):\n        if p=='QB': qb_idx_by_team.setdefault(t, []).append(i)\n\n    # Correlation heuristic\n    for i in range(n):\n        for j in range(i+1, n):\n            corr = cfg.cross_team_baseline\n            same_team = team[i]==team[j]\n            if same_team:\n                corr = cfg.base_same_team\n                # boost QB with pass catchers\n                if (pos[i]=='QB' and pos[j] in ('WR','TE','RB')) or (pos[j]=='QB' and pos[i] in ('WR','TE','RB')):\n                    corr += cfg.qb_receiver_boost\n                # mild positive kicker with offense\n                if (pos[i]=='K' and pos[j] in ('QB','WR','TE','RB')) or (pos[j]=='K' and pos[i] in ('QB','WR','TE','RB')):\n                    corr += cfg.k_vs_offense\n                # DSTs on same team with their offense: small (driven by field position/TDs)\n                if (pos[i]=='DST' and pos[j] in ('QB','WR','TE','RB','K')) or (pos[j]=='DST' and pos[i] in ('QB','WR','TE','RB','K')):\n                    corr += 0.05\n            else:\n                # cross-team relations\n                if (pos[i]=='DST' and pos[j] in ('QB','WR','TE','RB')) or (pos[j]=='DST' and pos[i] in ('QB','WR','TE','RB')):\n                    corr = cfg.dst_vs_opp_offense\n                if (pos[i]=='DST' and pos[j]=='DST'):\n                    corr = cfg.dsts_mutual\n                # very slight negative kicker vs opposing DST\n                if (pos[i]=='K' and pos[j]=='DST') or (pos[j]=='K' and pos[i]=='DST'):\n                    corr = min(corr, -0.05)\n\n            C[i,j] = C[j,i] = np.clip(corr, -0.95, 0.95)\n\n    # Ensure positive semidefinite by adding small ridge to diagonal if needed\n    # (nearest PSD via eigenvalue clipping)\n    eigvals, eigvecs = np.linalg.eigh(C)\n    min_e = eigvals.min()\n    if min_e < 1e-6:\n        eigvals = np.maximum(eigvals, 1e-6)\n        C = (eigvecs * eigvals) @ eigvecs.T\n        # normalize diagonal back to 1\n        d = np.sqrt(np.diag(C))\n        C = C / (d[:,None]*d[None,:] + 1e-12)\n    return C\n''')\nopen(os.path.join(base, 'data_io.py'), 'w', encoding='utf-8').write(r'''import pandas as pd\n\n# Expected headers:\n# Projections CSV:\n# 'RTS ID','player','position','team','salary','rushAtts','rushYds','rushTDs',\n# 'recvTgts','recvRec','recYds','recTDs','passAtts','passComp','passYds','passTDs','ints',\n# 'Proj Own','projected points'\n#\n# Leverage CSV:\n# 'Player','Pos','Team','Salary','FLEX Own','CPT Own','Total Own','FLEX Rate','CPT Rate',\n# 'Total Rate','CPT Lev','Total Lev'\n#\n# Percentiles CSV:\n# 'player','position','team','p000','p005',...,'p100'\n\ndef load_projections(path: str) -> pd.DataFrame:\n    df = pd.read_csv(path)\n    # normalize column names\n    cols = {c: c.strip() for c in df.columns}\n    df.rename(columns=cols, inplace=True)\n    # unify key names\n    df.rename(columns={\n        'player': 'Player',\n        'position': 'Pos',\n        'team': 'Team',\n        'salary': 'Salary',\n        'Proj Own': 'Total Own',\n        'projected points': 'ProjPts'\n    }, inplace=True)\n    # Fill missing Total Own if absent\n    if 'Total Own' not in df:\n        df['Total Own'] = 0.0\n    # Ensure dtypes\n    df['Salary'] = df['Salary'].astype(int)\n    if 'ProjPts' in df:\n        df['ProjPts'] = df['ProjPts'].astype(float)\n    return df\n\ndef load_leverage(path: str) -> pd.DataFrame:\n    df = pd.read_csv(path)\n    cols = {c: c.strip() for c in df.columns}\n    df.rename(columns=cols, inplace=True)\n    # Ensure dtypes\n    for col in ['FLEX Own','CPT Own','Total Own','FLEX Rate','CPT Rate','Total Rate','CPT Lev','Total Lev']:\n        if col in df:\n            df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0.0)\n    df['Salary'] = df['Salary'].astype(int)\n    return df\n\ndef load_percentiles(path: str) -> pd.DataFrame:\n    df = pd.read_csv(path)\n    cols = {c: c.strip() for c in df.columns}\n    df.rename(columns=cols, inplace=True)\n    df.rename(columns={\n        'player': 'Player',\n        'position': 'Pos',\n        'team': 'Team'\n    }, inplace=True)\n    # Ensure numeric percentiles\n    for c in df.columns:\n        if c.startswith('p'):\n            df[c] = pd.to_numeric(df[c], errors='coerce')\n    return df\n\ndef merge_inputs(proj_df: pd.DataFrame, lev_df: pd.DataFrame, pct_df: pd.DataFrame) -> pd.DataFrame:\n    # Merge on Player/Team/Pos; some CSVs might have casing mismatches\n    key_cols = ['Player','Pos','Team']\n    for df in (proj_df, lev_df, pct_df):\n        for k in key_cols:\n            if k in df:\n                df[k] = df[k].astype(str).str.strip()\n\n    df = proj_df.merge(lev_df, on=key_cols+['Salary'], how='left', suffixes=('','_lev'))\n    df = df.merge(pct_df, on=key_cols, how='left', suffixes=('','_pct'))\n\n    # Fallback rates if leverage missing\n    if 'CPT Rate' not in df: df['CPT Rate'] = 0.0\n    if 'FLEX Rate' not in df: df['FLEX Rate'] = 0.0\n    if 'Total Rate' not in df: df['Total Rate'] = df.get('Total Own', 0.0)\n\n    # Normalize CPT/FLEX rates if they exist but don't sum meaningfully\n    rates = df[['CPT Rate','FLEX Rate']].fillna(0.0)\n    if (rates.sum().sum() == 0) and ('Total Own' in df):\n        # derive naive split if only Total Own exists\n        df['CPT Rate'] = df['Total Own'] * 0.15\n        df['FLEX Rate'] = df['Total Own'] * 0.85\n\n    # Ensure projection fallback: use p50 if ProjPts missing\n    if 'ProjPts' not in df or df['ProjPts'].isna().all():\n        if 'p050' in df:\n            df['ProjPts'] = df['p050']\n        else:\n            df['ProjPts'] = 0.0\n\n    return df\n''')\nopen(os.path.join(base, 'ev.py'), 'w', encoding='utf-8').write(r'''import numpy as np\nimport pandas as pd\nfrom scipy.stats import norm\n\nfrom .percentiles import QuantileSampler\n\ndef _mvnorm_to_uniform(corr: np.ndarray, n_draws: int, rng) -> np.ndarray:\n    # Draw correlated normals then map to uniforms via Phi\n    Z = rng.multivariate_normal(mean=np.zeros(corr.shape[0]), cov=corr, size=n_draws)\n    U = 0.5*(1+erf(Z / np.sqrt(2)))  # manual Phi\n    return U\n\ndef erf(x):\n    # vectorized error function using np.erf if available, else approximation\n    try:\n        from math import erf as m_erf\n        vfunc = np.vectorize(m_erf)\n        return vfunc(x)\n    except Exception:\n        # Abramowitz & Stegun approximation\n        # Not perfect but fine for our use\n        sign = np.sign(x)\n        a1=0.254829592; a2=-0.284496736; a3=1.421413741; a4=-1.453152027; a5=1.061405429; p=0.3275911\n        t = 1.0/(1.0+p*np.abs(x))\n        y = 1.0 - (((((a5*t + a4)*t) + a3)*t + a2)*t + a1)*t*np.exp(-x*x)\n        return sign*y\n\nclass EVSimulator:\n    def __init__(self, players_df: pd.DataFrame, corr: np.ndarray, cfg):\n        self.df = players_df.reset_index(drop=True)\n        self.corr = corr\n        self.cfg = cfg\n        self.rng = np.random.default_rng(cfg.rng_seed+7)\n\n        # Build per-player quantile samplers\n        self.samplers = []\n        for _, row in self.df.iterrows():\n            pct = {c: row[c] for c in self.df.columns if c.startswith('p')}\n            self.samplers.append(QuantileSampler(pct))\n\n        # helpful map\n        self.idx_by_name = {row['Player']: i for i, row in self.df.iterrows()}\n\n    def simulate_points(self, n_sims: int):\n        # Gaussian copula to get correlated uniforms, then inverse CDF per player\n        U = self._correlated_uniforms(n_sims)\n        # Map to fantasy points per player (vectorized)\n        pts = np.zeros((n_sims, len(self.df)), dtype=float)\n        for j, sampler in enumerate(self.samplers):\n            pts[:, j] = sampler.sample(U[:, j])\n        return pts  # shape (n_sims, n_players)\n\n    def _correlated_uniforms(self, n_sims: int):\n        # Use eigen-decomposition for speed / stability\n        vals, vecs = np.linalg.eigh(self.corr)\n        vals = np.clip(vals, 1e-8, None)\n        A = vecs @ np.diag(np.sqrt(vals))\n        Z = self.rng.standard_normal(size=(n_sims, self.corr.shape[0]))\n        X = Z @ A.T\n        # standard normal CDF\n        U = 0.5 * (1.0 + erf(X / np.sqrt(2)))\n        return U\n\n    def lineup_scores(self, pts_mat: np.ndarray, lineup_df: pd.DataFrame) -> np.ndarray:\n        # lineup_df columns: CPT, FLEX1..FLEX5\n        idx = self.idx_by_name\n        n = len(lineup_df)\n        scores = np.zeros((pts_mat.shape[0], n), dtype=float)\n        for k, row in lineup_df.iterrows():\n            names = [row['CPT'], row['FLEX1'], row['FLEX2'], row['FLEX3'], row['FLEX4'], row['FLEX5']]\n            idcs = [idx[nm] for nm in names]\n            # CPT 1.5x\n            s = 1.5*pts_mat[:, idcs[0]] + pts_mat[:, idcs[1]] + pts_mat[:, idcs[2]] + pts_mat[:, idcs[3]] + pts_mat[:, idcs[4]] + pts_mat[:, idcs[5]]\n            scores[:, k] = s\n        return scores\n\n    def expected_value(self, our_lineups: pd.DataFrame, field_lineups: pd.DataFrame) -> pd.Series:\n        n_sims = self.cfg.n_sims\n        # Simulate points for all unique players\n        pts = self.simulate_points(n_sims)\n\n        # Scores\n        our_scores = self.lineup_scores(pts, our_lineups)\n        field_scores = self.lineup_scores(pts, field_lineups)\n\n        # For each sim: find best score among field + our 10; tally prize split\n        ev = np.zeros(our_lineups.shape[0], dtype=float)\n\n        for t in range(n_sims):\n            # combine scores\n            all_scores = np.concatenate([our_scores[t], field_scores[t]])\n            top = all_scores.max()\n            # which our lineups tie top?\n            ours_tie = np.where(our_scores[t] >= top - 1e-9)[0]\n            # how many total tied?\n            total_tie = (all_scores >= top - 1e-9).sum()\n\n            if len(ours_tie) > 0:\n                split = self.cfg.prize_first / total_tie\n                ev[ours_tie] += split\n\n        # average across sims\n        return pd.Series(ev / n_sims, index=our_lineups.index, name='EV')\n''')\nopen(os.path.join(base, 'generator.py'), 'w', encoding='utf-8').write(r'''import numpy as np\nimport pandas as pd\nfrom itertools import combinations\nfrom .lineup import is_valid_lineup, apply_cpt_salary\n\nclass CandidateGenerator:\n    def __init__(self, df: pd.DataFrame, cfg):\n        self.df = df.reset_index(drop=True)\n        self.cfg = cfg\n        self.rng = np.random.default_rng(cfg.rng_seed)\n\n        # Precompute p50 and ranks\n        self.df['p50'] = self.df.get('p050', self.df['ProjPts'])\n        self.df.sort_values('p50', ascending=False, inplace=True)\n        self.df.reset_index(drop=True, inplace=True)\n\n    def _filtered_pool(self):\n        # Limit pool sizes to keep enumeration feasible\n        # Take top-K CPT candidates by p50, and top-K flex candidates overall\n        cpt_candidates = self.df.head(self.cfg.cpt_top_k).copy()\n\n        # Flex pool: take top flex_top_k overall + a few random longshots for leverage\n        flex_top = self.df.head(self.cfg.flex_top_k).copy()\n        longshots = self.df.iloc[self.cfg.flex_top_k:].sample(\n            n=min(10, max(0, len(self.df)-self.cfg.flex_top_k)),\n            random_state=self.cfg.rng_seed\n        ) if len(self.df) > self.cfg.flex_top_k else self.df.iloc[0:0]\n        flex_pool = pd.concat([flex_top, longshots], ignore_index=True).drop_duplicates(subset=['Player'])\n\n        return cpt_candidates, flex_pool\n\n    def generate(self, max_salary: int=None, leave_salary_max: int=None, n_samples: int=None):\n        max_salary = max_salary or self.cfg.max_salary\n        leave_salary_max = leave_salary_max if leave_salary_max is not None else self.cfg.leave_salary_max\n        target_min_salary = max_salary - leave_salary_max\n\n        cpt_candidates, flex_pool = self._filtered_pool()\n\n        # Pre-index by player for quick lookups\n        by_name = self.df.set_index('Player')\n\n        # Build candidate flex combinations with pruning via simple greedy sampling\n        names = flex_pool['Player'].tolist()\n        candidates = set()\n\n        # We'll sample combinations rather than brute-force all C( |pool|, 5 )\n        trials = n_samples or self.cfg.candidate_pool_size * 5\n\n        for _ in range(trials):\n            # Randomly bias toward higher p50\n            probs = flex_pool['p50'].to_numpy()\n            probs = probs / probs.sum()\n            picks = self.rng.choice(len(names), size=5, replace=False, p=probs)\n            flex_names = [names[i] for i in picks]\n\n            # Loop CPTs\n            for _, row in cpt_candidates.iterrows():\n                cpt = row['Player']\n                ok, sal, teams = is_valid_lineup(flex_names, cpt, by_name.reset_index(), max_salary)\n                if not ok: \n                    continue\n                if sal < target_min_salary: \n                    continue\n                lineup_key = (cpt,) + tuple(sorted(flex_names))\n                candidates.add(lineup_key)\n                if len(candidates) >= self.cfg.candidate_pool_size:\n                    break\n            if len(candidates) >= self.cfg.candidate_pool_size:\n                break\n\n        # Return as DataFrame\n        out = []\n        for key in candidates:\n            cpt = key[0]; flex = key[1:]\n            sal = apply_cpt_salary(int(by_name.loc[cpt,'Salary'])) + int(by_name.loc[list(flex),'Salary'].sum())\n            out.append({'CPT': cpt, 'FLEX1': flex[0], 'FLEX2': flex[1], 'FLEX3': flex[2], 'FLEX4': flex[3], 'FLEX5': flex[4], 'Salary': sal})\n        return pd.DataFrame(out)\n''')\nopen(os.path.join(base, 'lineup.py'), 'w', encoding='utf-8').write(r'''from dataclasses import dataclass\nfrom typing import List, Dict, Tuple\nimport numpy as np\nimport pandas as pd\n\nALLOWED_POS = {'QB','WR','RB','TE','K','DST'}\n\n@dataclass(frozen=True)\nclass Lineup:\n    cpt: str              # player name @ CPT\n    flex: Tuple[str,...]  # 5 player names\n    salary: int\n    teams: Tuple[str,...] # teams present\n    players: Tuple[str,...] # all 6 names (CPT duplicates prevented upstream)\n\ndef apply_cpt_salary(base_salary: int) -> int:\n    # EXACT 1.5x (no rounding beyond int)\n    return int(round(1.5 * base_salary))\n\ndef is_valid_lineup(names: List[str], cpt_name: str, df: pd.DataFrame, max_salary: int) -> Tuple[bool,int,Tuple[str,...]]:\n    # Ensure no duplicate CPT in flex, both teams present, salary cap\n    if cpt_name in names:\n        return False, 0, ()\n    all_names = [cpt_name] + names\n    rows = df.set_index('Player').loc[all_names]\n    salary = apply_cpt_salary(int(rows.loc[cpt_name,'Salary'])) + int(rows.loc[names, 'Salary'].sum())\n    if salary > max_salary:\n        return False, salary, ()\n    teams = set(rows['Team'].tolist())\n    if len(teams) < 2:\n        return False, salary, ()\n    return True, salary, tuple(teams)\n\ndef validate_player_pool(df: pd.DataFrame) -> pd.DataFrame:\n    # Filter to allowed positions and players expected active\n    df = df[df['Pos'].isin(ALLOWED_POS)].copy()\n    # basic sanity\n    df = df.dropna(subset=['Player','Pos','Team','Salary','ProjPts'])\n    return df\n''')\nopen(os.path.join(base, 'opponent.py'), 'w', encoding='utf-8').write(r'''import numpy as np\nimport pandas as pd\nfrom .lineup import is_valid_lineup, apply_cpt_salary\n\nclass OpponentField:\n    def __init__(self, players_df: pd.DataFrame, cfg):\n        self.df = players_df.reset_index(drop=True)\n        self.cfg = cfg\n        self.rng = np.random.default_rng(cfg.rng_seed)\n\n        # Rates used for sampling\n        self.cpt_rates = np.clip(self.df['CPT Rate'].fillna(0.0).to_numpy(), 0, None)\n        self.flex_rates = np.clip(self.df['FLEX Rate'].fillna(0.0).to_numpy(), 0, None)\n        if self.cpt_rates.sum() == 0:\n            # derive naive split: small CPT share\n            tot = self.df['Total Own'].fillna(0.0).to_numpy()\n            self.cpt_rates = 0.15 * tot\n            self.flex_rates = 0.85 * tot\n\n        # Normalize\n        self.cpt_rates = self.cpt_rates / (self.cpt_rates.sum() + 1e-9)\n        self.flex_rates = self.flex_rates / (self.flex_rates.sum() + 1e-9)\n\n    def _sample_lineup_by_rates(self):\n        names = self.df['Player'].tolist()\n        # pick CPT by CPT rates\n        cpt_idx = self.rng.choice(len(names), p=self.cpt_rates)\n        cpt = names[cpt_idx]\n\n        # pick flex by FLEX rates without replacement\n        # to encourage diversity, draw more than 5 then keep top-5 unique by descending draw prob * random\n        idxs = self.rng.choice(len(names), size=8, replace=False, p=self.flex_rates)\n        flex = []\n        for i in idxs:\n            if names[i]==cpt: continue\n            flex.append(names[i])\n            if len(flex)==5: break\n        if len(flex)<5:\n            # fallback: fill randomly\n            remaining = [n for n in names if n not in flex and n!=cpt]\n            self.rng.shuffle(remaining)\n            flex += remaining[:5-len(flex)]\n\n        # check validity\n        ok, sal, teams = is_valid_lineup(flex, cpt, self.df, self.cfg.max_salary)\n        if not ok: return None\n        return (cpt, tuple(sorted(flex)), sal)\n\n    def bank_field_lineups(self, bank_size=None):\n        bank_size = bank_size or self.cfg.field_portfolio_size\n        seen = set()\n        bank = []\n        tries = 0\n        while len(bank) < bank_size and tries < bank_size*20:\n            line = self._sample_lineup_by_rates()\n            tries += 1\n            if line is None: \n                continue\n            key = (line[0], line[1])\n            if key in seen: \n                continue\n            seen.add(key)\n            bank.append({'CPT': line[0], 'FLEX': line[1], 'Salary': line[2]})\n        return pd.DataFrame(bank)\n\n    def sample_field_entries(self, bank: pd.DataFrame, n_entries: int):\n        # Sample with weights influenced by total ownership of the 6 players\n        if len(bank)==0:\n            return pd.DataFrame(columns=['CPT','FLEX','Salary'])\n        weights = []\n        own_map = self.df.set_index('Player')['Total Rate'].fillna(0.0).to_dict()\n        for _,r in bank.iterrows():\n            pts = sum(own_map.get(p,0.0) for p in ([r['CPT']] + list(r['FLEX'])))\n            weights.append(pts)\n        w = np.array(weights); w = w / (w.sum()+1e-9)\n        idx = np.random.default_rng(self.cfg.rng_seed+1).choice(len(bank), size=n_entries, replace=True, p=w)\n        return bank.iloc[idx].reset_index(drop=True)\n''')\nopen(os.path.join(base, 'percentiles.py'), 'w', encoding='utf-8').write(r'''import numpy as np\n\nclass QuantileSampler:\n    \"\"\"Piecewise-linear inverse CDF built from provided percentiles p000..p100.\"\"\"\n    def __init__(self, percentiles: dict):\n        # percentiles: key -> value mapping for columns like 'p000','p005',...,'p100'\n        # Build sorted (q, x) arrays where q in [0,1]\n        qs, xs = [], []\n        for k, v in percentiles.items():\n            if k.startswith('p') and v is not None and not np.isnan(v):\n                try:\n                    q = int(k[1:]) / 100.0  # e.g., 'p005' -> 5 -> 0.05\n                except:\n                    continue\n                qs.append(q); xs.append(float(v))\n        if len(qs) < 2:\n            # fallback to degenerate distribution at 0\n            qs = [0.0, 1.0]; xs = [0.0, 0.0]\n        order = np.argsort(qs)\n        self.q = np.array(qs)[order]\n        self.x = np.array(xs)[order]\n\n        # Enforce monotonicity in xs to avoid tiny inversions\n        self.x = np.maximum.accumulate(self.x)\n\n        # cache bounds\n        self.x_min = self.x[0]\n        self.x_max = self.x[-1]\n\n    def sample(self, u: np.ndarray) -> np.ndarray:\n        \"\"\"Map uniforms u in [0,1] to samples via piecewise-linear inverse CDF.\"\"\"\n        u = np.clip(u, 0.0, 1.0)\n        return np.interp(u, self.q, self.x)\n\n    def mean(self) -> float:\n        # approximate mean via trapezoidal integration of inverse CDF\n        # E[X] = \\int_0^1 Q(u) du ~ average of knots\n        return float(np.trapz(self.x, self.q) / (self.q[-1]-self.q[0] if self.q[-1]>self.q[0] else 1.0))\n''')\nopen(os.path.join(base, 'portfolio.py'), 'w', encoding='utf-8').write(r'''import numpy as np\nimport pandas as pd\n\ndef _overlap(a_row, b_row):\n    a = set([a_row['CPT'], a_row['FLEX1'], a_row['FLEX2'], a_row['FLEX3'], a_row['FLEX4'], a_row['FLEX5']])\n    b = set([b_row['CPT'], b_row['FLEX1'], b_row['FLEX2'], b_row['FLEX3'], b_row['FLEX4'], b_row['FLEX5']])\n    return len(a & b)\n\nclass PortfolioOptimizer:\n    def __init__(self, cfg):\n        self.cfg = cfg\n\n    def select(self, candidates: pd.DataFrame, ev: pd.Series):\n        # Greedy submodular-like selection:\n        # maximize EV while enforcing max overlap and mild CPT diversity, salary leave <= cfg.leave_salary_max\n        df = candidates.copy()\n        df = df.join(ev)\n        df = df.sort_values('EV', ascending=False).reset_index(drop=True)\n\n        chosen_idx = []\n        cpts_used = set()\n\n        for i, row in df.iterrows():\n            if len(chosen_idx) >= self.cfg.our_entries:\n                break\n            # overlap constraint\n            ok = True\n            for j in chosen_idx:\n                if _overlap(row, df.loc[j]) > self.cfg.max_overlap:\n                    ok = False; break\n            if not ok: \n                continue\n            # Optional CPT uniqueness encouragement (not strict)\n            if self.cfg.enforce_unique_cpt and row['CPT'] in cpts_used:\n                continue\n\n            chosen_idx.append(i)\n            cpts_used.add(row['CPT'])\n\n        return df.loc[chosen_idx].reset_index(drop=True)\n''')\nopen(os.path.join(base, 'run_example.py'), 'w', encoding='utf-8').write(r'''\n# Example runner for Colab using direct GitHub RAW links.\nimport pandas as pd\nfrom .config import SimConfig\nfrom .data_io import load_projections, load_leverage, load_percentiles, merge_inputs\nfrom .lineup import validate_player_pool\nfrom .generator import CandidateGenerator\nfrom .correlation import build_correlation\nfrom .opponent import OpponentField\nfrom .ev import EVSimulator\nfrom .portfolio import PortfolioOptimizer\n\ndef run(proj_csv, lev_csv, pct_csv):\n    cfg = SimConfig()\n    proj = load_projections(proj_csv)    # accepts local path or https raw link\n    lev  = load_leverage(lev_csv)\n    pct  = load_percentiles(pct_csv)\n    players = merge_inputs(proj, lev, pct)\n    players = validate_player_pool(players)\n\n    gen = CandidateGenerator(players, cfg)\n    cands = gen.generate()\n\n    C = build_correlation(players, cfg)\n    opp = OpponentField(players, cfg)\n    bank = opp.bank_field_lineups()\n    field = opp.sample_field_entries(bank, n_entries=cfg.field_size - cfg.our_entries)\n\n    sim = EVSimulator(players, C, cfg)\n    ev = sim.expected_value(cands, field)\n\n    port = PortfolioOptimizer(cfg)\n    chosen = port.select(cands, ev)\n\n    return chosen, ev.sort_values(ascending=False).head(20)\n\nif __name__ == \"__main__\":\n    # Paste your RAW GitHub URLs here (must start with https://raw.githubusercontent.com/...)\n    projections_url  = \"https://raw.githubusercontent.com/<user>/<repo>/<branch>/projections.csv\"\n    leverage_url     = \"https://raw.githubusercontent.com/<user>/<repo>/<branch>/leverage.csv\"\n    percentiles_url  = \"https://raw.githubusercontent.com/<user>/<repo>/<branch>/percentiles.csv\"\n\n    chosen, top = run(projections_url, leverage_url, percentiles_url)\n    print(chosen)\n    print(top)\n''')", "outputs": []}, {"id": "b3086176", "cell_type": "code", "metadata": {}, "execution_count": null, "source": "\n# === 3) Import the package we just wrote ===\nimport sys, os\nsys.path.append('/content/showdown_ev')\nfrom showdown.config import SimConfig\nfrom showdown.data_io import load_projections, load_leverage, load_percentiles, merge_inputs\nfrom showdown.lineup import validate_player_pool\nfrom showdown.generator import CandidateGenerator\nfrom showdown.correlation import build_correlation\nfrom showdown.opponent import OpponentField\nfrom showdown.ev import EVSimulator\nfrom showdown.portfolio import PortfolioOptimizer\n\nprint(\"Package imported.\")\n", "outputs": []}, {"id": "6e5a7289", "cell_type": "code", "metadata": {}, "execution_count": null, "source": "\n# === 4) Load data, simulate, and select portfolio ===\nimport pandas as pd\n\ncfg = SimConfig(**CFG_KW)\n\nproj = load_projections(PROJECTIONS_URL)\nlev  = load_leverage(LEVERAGE_URL)\npct  = load_percentiles(PERCENTILES_URL)\nplayers = merge_inputs(proj, lev, pct)\nplayers = validate_player_pool(players)\n\ngen = CandidateGenerator(players, cfg)\ncands = gen.generate()\n\nC = build_correlation(players, cfg)\nopp = OpponentField(players, cfg)\nbank = opp.bank_field_lineups()\nfield = opp.sample_field_entries(bank, n_entries=cfg.field_size - cfg.our_entries)\n\nsim = EVSimulator(players, C, cfg)\nev = sim.expected_value(cands, field)\n\nport = PortfolioOptimizer(cfg)\nchosen = port.select(cands, ev)\n\n# Show and save outputs\ndisplay_cols = ['CPT','FLEX1','FLEX2','FLEX3','FLEX4','FLEX5','Salary']\nout_chosen = chosen[display_cols + ['EV']].copy()\nout_top = cands.join(ev).sort_values('EV', ascending=False).head(20)[display_cols + ['EV']].reset_index(drop=True)\n\nprint(\"=== Selected 10 lineups ===\")\ndisplay(out_chosen.reset_index(drop=True))\nprint(\"=== Top-20 EV candidates ===\")\ndisplay(out_top)\n\nout_chosen.to_csv('/content/chosen_lineups.csv', index=False)\nout_top.to_csv('/content/top20_ev_candidates.csv', index=False)\nprint(\"Saved /content/chosen_lineups.csv and /content/top20_ev_candidates.csv\")\n", "outputs": []}]}